{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##0.Librerías necesarias"
      ],
      "metadata": {
        "id": "xS1T-vQSdLoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install rarfile\n",
        "#!pip install unzip\n",
        "!pip install stop-words\n",
        "!pip install num2words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca-qFp4k0mzh",
        "outputId": "f02b2c4a-e4c7-45d0-96db-3335c171b6f6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.8/dist-packages (2018.7.23)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.8/dist-packages (0.5.12)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from num2words) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts7qrXDUf31r",
        "outputId": "4ad6c11e-5942-47f6-ff88-f4efb672bbea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.8/dist-packages (1.8.2.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from wordcloud) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from wordcloud) (3.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from wordcloud) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->wordcloud) (4.38.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4z0nTzWSbUTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177bbf68-3a1b-42a5-9f9d-453d8df45ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Librerias necesarias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import random\n",
        "#import rarfile # para descomprimir archivos\n",
        "import json\n",
        "#import csv \n",
        "#para limpiar los datos\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('omw-1.4')\n",
        "import string\n",
        "import unicodedata\n",
        "from num2words import num2words\n",
        "#para reducir la dimensión\n",
        "from sklearn.manifold import TSNE\n",
        "#para representar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#análisis exloratorio\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "from nltk.probability import FreqDist\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "#preprocesado\n",
        "from stop_words import get_stop_words\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "#modelado\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "#reporte\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Carga de datos"
      ],
      "metadata": {
        "id": "ldJRNKDHdFWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Montamos GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMR7XcldYvEs",
        "outputId": "4c9dab07-bca0-4653-ecc3-c49c61afcad0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cargamos los datos necesarios desde nuestro google drive\n",
        "path = '/content/drive/MyDrive/NLP/'\n",
        "\n",
        "train_clean = pd.read_csv(f'{path}train_clean.csv')\n",
        "test_clean= pd.read_csv(f'{path}test_clean.csv')"
      ],
      "metadata": {
        "id": "2hC4pao7x_0s"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "OCf5Zhqj1T9c",
        "outputId": "0544c204-8621-4a69-9ba5-7ef6f5153665"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           review_clean  sentiment_label\n",
              "0     pie arrived wa missing one ordered topping pay...                1\n",
              "1     burger wa fabulous bacon tasted like one green...                0\n",
              "2                        food wa good chicken spam meat                1\n",
              "3                    solid taco place tortilla bit soft                1\n",
              "4     mahi mahi taco pretty good landlocked tucson c...                1\n",
              "...                                                 ...              ...\n",
              "4760  ok burger price fry usually dont like kind dry...                1\n",
              "4761  ordered cheesy todd cheeseburger ha bacon jala...                1\n",
              "4762  coffee surprisingly good omeletes well made an...                1\n",
              "4763               secret theyve got best burger around                0\n",
              "4764  inside light wa gloomy anyway gave complementa...                1\n",
              "\n",
              "[4765 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b03dd9dc-322e-4455-b34a-66e52172ff89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_clean</th>\n",
              "      <th>sentiment_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pie arrived wa missing one ordered topping pay...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>burger wa fabulous bacon tasted like one green...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>food wa good chicken spam meat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>solid taco place tortilla bit soft</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mahi mahi taco pretty good landlocked tucson c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4760</th>\n",
              "      <td>ok burger price fry usually dont like kind dry...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4761</th>\n",
              "      <td>ordered cheesy todd cheeseburger ha bacon jala...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4762</th>\n",
              "      <td>coffee surprisingly good omeletes well made an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4763</th>\n",
              "      <td>secret theyve got best burger around</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4764</th>\n",
              "      <td>inside light wa gloomy anyway gave complementa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4765 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b03dd9dc-322e-4455-b34a-66e52172ff89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b03dd9dc-322e-4455-b34a-66e52172ff89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b03dd9dc-322e-4455-b34a-66e52172ff89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "viRewjZN1T_3",
        "outputId": "a61051c6-b433-4a6e-b0f4-f23154ced2f2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           review_clean  sentiment_label\n",
              "0     next time want order bibim naengmyeon dumpling...                0\n",
              "1     love place exelent steak chumichurri steak per...                0\n",
              "2     server suggested salt vinegar seasoning tater ...                1\n",
              "3     green bean shriveled quite honestly worst gree...                1\n",
              "4     one put sign saying chicken fried nationwell k...                1\n",
              "...                                                 ...              ...\n",
              "1584  love seafood place sits right water front lot ...                0\n",
              "1585  starter fritto miso fried calamari zucchini sh...                0\n",
              "1586  aw ha always smooth root beer forgotten sweet ...                0\n",
              "1587  tilapia crispy taste okay onion ring little bl...                1\n",
              "1588  frose wa tasty 1st course wa chicken sausage g...                0\n",
              "\n",
              "[1589 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b6a6a10-2b35-4311-abf4-134185228c74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_clean</th>\n",
              "      <th>sentiment_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>next time want order bibim naengmyeon dumpling...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love place exelent steak chumichurri steak per...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>server suggested salt vinegar seasoning tater ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>green bean shriveled quite honestly worst gree...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one put sign saying chicken fried nationwell k...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1584</th>\n",
              "      <td>love seafood place sits right water front lot ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1585</th>\n",
              "      <td>starter fritto miso fried calamari zucchini sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1586</th>\n",
              "      <td>aw ha always smooth root beer forgotten sweet ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1587</th>\n",
              "      <td>tilapia crispy taste okay onion ring little bl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1588</th>\n",
              "      <td>frose wa tasty 1st course wa chicken sausage g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1589 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b6a6a10-2b35-4311-abf4-134185228c74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b6a6a10-2b35-4311-abf4-134185228c74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b6a6a10-2b35-4311-abf4-134185228c74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split de los datos"
      ],
      "metadata": {
        "id": "tUVfa3vx2MMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dividimos con las columnas 'processedReview' y las etiquetas 'sentiment_label'\n",
        "\n",
        "#split conjunto de train\n",
        "X_train = train_clean['review_clean']\n",
        "y_train = train_clean['sentiment_label']\n",
        "\n",
        "#split conjunto de test\n",
        "X_test = train_clean['review_clean']\n",
        "y_test = train_clean['sentiment_label']\n"
      ],
      "metadata": {
        "id": "DhrUMfLGFliA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.iloc[:10]"
      ],
      "metadata": {
        "id": "eoxqnx0_FlkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69444555-ffee-41e1-e5e5-9c870c97d6c6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    pie arrived wa missing one ordered topping pay...\n",
              "1    burger wa fabulous bacon tasted like one green...\n",
              "2                       food wa good chicken spam meat\n",
              "3                   solid taco place tortilla bit soft\n",
              "4    mahi mahi taco pretty good landlocked tucson c...\n",
              "5    photograph speak volume taste delivered smoke ...\n",
              "6          fry die fried cod sandwich wa best ive ever\n",
              "7     crab soup delicious sandwich poboys taco awesome\n",
              "8    people working need smile music yes place need...\n",
              "9    ive tried variety sushi roll good yama salad w...\n",
              "Name: review_clean, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.iloc[:10]"
      ],
      "metadata": {
        "id": "RlOHW790Flmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059dbc67-3245-40d0-ba2e-02858915ec49"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    0\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "5    0\n",
              "6    0\n",
              "7    0\n",
              "8    1\n",
              "9    0\n",
              "Name: sentiment_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracción de características"
      ],
      "metadata": {
        "id": "Gvh9LuD-bqOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtraction():\n",
        "  def __init__(self, max_df: float=0.95, min_df: int=3, max_features: int =2500, ngram_range: tuple=(1, 3)):\n",
        "    \"\"\"Instanciamos dentro de la propia clase las clases TfidfVectorizer, CountVectorizer y SelectKBest\"\"\"\n",
        "    self.tdidf = TfidfVectorizer(\n",
        "                max_df=max_df,\n",
        "                min_df=min_df,\n",
        "                max_features=max_features,\n",
        "                strip_accents='ascii',\n",
        "                ngram_range=ngram_range\n",
        "            )\n",
        "    self.vectorizer = CountVectorizer()\n",
        "    self.selector = selector = SelectKBest(chi2)\n",
        "  \n",
        "  def run(self,X_train: pd.Series, X_test: pd.Series, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
        "    #Realizamos el tdidf\n",
        "    X_train_tdif, X_test_tdif = self.tdidfTraining(X_train=X_train, X_test = X_test)\n",
        "    #Realizamos el count vectorizer\n",
        "    X_train__vec, X_test_vec = self.countVectorizerTraining(X_train=X_train, X_test = X_test)\n",
        "\n",
        "    #Realizamos la seleccion chi2\n",
        "    X_train_tdif_best, X_test_tdif_best = self.selectKBestChi(X_train = X_train_tdif, X_test= X_test_tdif, y_train= y_train, y_test= y_test)\n",
        "    X_train_vec_best, X_test_vec_best = self.selectKBestChi(X_train = X_train__vec, X_test= X_test_vec, y_train= y_train, y_test= y_test)\n",
        "    #Almacenamos todos los sets en un diccionario\n",
        "    dic_best_set = {'X_train_tdif_best': X_train_tdif_best, 'X_train_vec_best': X_train_vec_best, 'X_test_tdif_best': X_test_tdif_best, 'X_test_vec_best': X_test_vec_best}\n",
        "    return dic_best_set\n",
        "\n",
        "  def tdidfTraining(self, X_train: pd.Series, X_test: pd.Series) -> tuple:\n",
        "    \"\"\"funcion que  realiza el entrenamiento de tdidf y transforma el set de train y test\n",
        "    : param X_train: pd.Series con los datos de train\n",
        "    : param X_test: pd.Series con los datos de test\n",
        "    : return: tupla con las series transformadas X_train_tdif, X_test_tdif\"\"\"\n",
        "    #Entrenamos el modelo a través de la instancia self.tdidf\n",
        "    print(f'[INFO] Realizando entrenamiento {type(self.tdidf).__name__}...')\n",
        "    self.tdidf.fit(X_train)\n",
        "    #Obtenemos los set de datos modificados con tdif\n",
        "    print(f'[INFO] Realizando transformacion de tipo {type(self.tdidf).__name__}...')\n",
        "    X_train_tdif = self.tdidf.transform(X_train)\n",
        "    X_test_tdif = self.tdidf.transform(X_test)\n",
        "    return X_train_tdif, X_test_tdif\n",
        "\n",
        "  def countVectorizerTraining(self, X_train: pd.Series, X_test: pd.Series) -> tuple:\n",
        "    \"\"\"funcion que  realiza el entrenamiento de countVectorizer y transforma el set de train y test\n",
        "    : param X_train: pd.Series con los datos de train\n",
        "    : param X_test: pd.Series con los datos de test\n",
        "    : return: tupla con las series transformadas X_train_vec, X_test_vec\"\"\"\n",
        "    #Realizamos el entrenamiento y la transformación de train\n",
        "    print(f'[INFO] Realizando entrenamiento {type(self.vectorizer).__name__}...')\n",
        "    X_train_vec = self.vectorizer.fit_transform(X_train)\n",
        "    #Realizamos la transformación de test\n",
        "    print(f'[INFO] Realizando transformacion de tipo {type(self.vectorizer).__name__}...')\n",
        "    X_test_vec = self.vectorizer.transform(X_test)\n",
        "    return X_train_vec,X_test_vec\n",
        "\n",
        "  def selectKBestChi(self, X_train: pd.Series, X_test: pd.Series, y_train: pd.Series, y_test: pd.Series) -> tuple:\n",
        "    \"\"\"funcion que  realiza la selección de las mejores características del conjunto de train\n",
        "    : param X_train: pd.Series con los datos de train\n",
        "    : param X_test: pd.Series con los datos de test\n",
        "    : param y_train: pd.Series con las etiquetas de train\n",
        "    : param y_test: pd.Series con las etiquetas de test\n",
        "    : return: tupla con las series transformadas X_train_best, X_test_best\"\"\"\n",
        "    #Realizamos el entrenamiento y la extracción de train\n",
        "    print(f'[INFO] Realizando entrenamiento {type(self.selector).__name__}...')\n",
        "    X_train_best = self.selector.fit_transform(X_train, y_train)\n",
        "    #Realizamos la transformación de test\n",
        "    print(f'[INFO] Realizando transformacion de tipo {type(self.vectorizer).__name__}...')\n",
        "    X_test_best = self.selector.transform(X_test)\n",
        "    return X_train_best, X_test_best"
      ],
      "metadata": {
        "id": "XPkGnxJC2Cox"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fe = FeatureExtraction()\n",
        "\n",
        "# Utilizamos el método run para obtener los mejores resultados\n",
        "resultados = fe.run(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRSbNSyw3HOf",
        "outputId": "b559ab7f-8951-4b37-84a6-752d3316dbe6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Realizando entrenamiento TfidfVectorizer...\n",
            "[INFO] Realizando transformacion de tipo TfidfVectorizer...\n",
            "[INFO] Realizando entrenamiento CountVectorizer...\n",
            "[INFO] Realizando transformacion de tipo CountVectorizer...\n",
            "[INFO] Realizando entrenamiento SelectKBest...\n",
            "[INFO] Realizando transformacion de tipo CountVectorizer...\n",
            "[INFO] Realizando entrenamiento SelectKBest...\n",
            "[INFO] Realizando transformacion de tipo CountVectorizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados"
      ],
      "metadata": {
        "id": "KZvITKr6AL0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3613382b-e710-420f-925d-fba038e356a9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X_train_tdif_best': <4765x10 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 3758 stored elements in Compressed Sparse Row format>,\n",
              " 'X_train_vec_best': <4765x10 sparse matrix of type '<class 'numpy.int64'>'\n",
              " \twith 5031 stored elements in Compressed Sparse Row format>,\n",
              " 'X_test_tdif_best': <4765x10 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 3758 stored elements in Compressed Sparse Row format>,\n",
              " 'X_test_vec_best': <4765x10 sparse matrix of type '<class 'numpy.int64'>'\n",
              " \twith 5031 stored elements in Compressed Sparse Row format>}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mA-x6Ss5B35J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bGWhluozB37h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NsYJ_K44B3-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer simple\n",
        "#cv_simple = CountVectorizer()\n",
        "#X_train_cv_simple = cv_simple.fit_transform(df_train['review_text'])\n",
        "#X_test_cv_simple = cv_simple.transform(df_test['review_text'])\n",
        "\n",
        "# CountVectorizer con ngrams, max_features, min_df y max_df\n",
        "cv_complex = CountVectorizer(ngram_range=(1, 2), max_features=1000, max_df=0.95, min_df=5)\n",
        "X_train_cv_complex = cv_complex.fit_transform(df_train['review_text']).toarray() #.toarray() para plotearlo\n",
        "X_test_cv_complex = cv_complex.transform(df_test['review_text']).toarray()\n",
        "\n",
        "# TfIdfVectorizer simple\n",
        "#tfidf_simple = TfidfVectorizer()\n",
        "#X_train_tfidf_simple = tfidf_simple.fit_transform(df_train['review_text'])\n",
        "#X_test_tfidf_simple = tfidf_simple.transform(df_test['review_text'])\n",
        "\n",
        "# TfIdfVectorizer complejo\n",
        "tfidf_complex = TfidfVectorizer(ngram_range=(1, 2), max_features=1000, max_df=0.95, min_df=5)\n",
        "X_train_tfidf_complex = tfidf_complex.fit_transform(df_train['review_text'])\n",
        "X_test_tfidf_complex = tfidf_complex.transform(df_test['review_text'])"
      ],
      "metadata": {
        "id": "cwEpPTP7_fPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mk_E3-Jz_slX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_h6PAIkQmUic"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIaABwf0mUic"
      },
      "outputs": [],
      "source": [
        "#lr_cv_simple = LogisticRegression()\n",
        "lr_cv_complex = LogisticRegression()\n",
        "#lr_tfidf_simple = LogisticRegression()\n",
        "lr_tfidf_complex = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjU6iEpBmUid"
      },
      "outputs": [],
      "source": [
        "#lr_cv_simple.fit(X_train_cv_simple, df_train['sentiment_label'])  # train\n",
        "#y_pred_cv_simple = lr_cv_simple.predict(X_test_cv_simple)  # test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "dHbDnHLbmUid"
      },
      "outputs": [],
      "source": [
        "lr_cv_complex.fit(X_train_cv_complex, df_train['sentiment_label'])  # train\n",
        "y_pred_cv_complex = lr_cv_complex.predict(X_test_cv_complex)  # test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA8YodOEmUid"
      },
      "outputs": [],
      "source": [
        "#lr_tfidf_simple.fit(X_train_tfidf_simple, df_train['sentiment_label'])  # train\n",
        "#y_pred_tfidf_simple = lr_tfidf_simple.predict(X_test_tfidf_simple)  # test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4pyGEhcmUid"
      },
      "outputs": [],
      "source": [
        "lr_tfidf_complex.fit(X_train_tfidf_complex, df_train['sentiment_label'])  # train\n",
        "y_pred_tfidf_complex = lr_tfidf_complex.predict(X_test_tfidf_complex)  # test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print('CountVectorizer simple\\n')\n",
        "#print(confusion_matrix(df_test['sentiment_label'], y_pred_cv_simple))\n",
        "#print(classification_report(df_test['sentiment_label'], y_pred_cv_simple))"
      ],
      "metadata": {
        "id": "Opbo6YMFu7tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('CountVectorizer complejo\\n')\n",
        "print(confusion_matrix(df_test['sentiment_label'], y_pred_cv_complex))\n",
        "print(classification_report(df_test['sentiment_label'], y_pred_cv_complex))"
      ],
      "metadata": {
        "id": "Kw68lN04u_-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print('TfIdfVectorizer simple\\n')\n",
        "#print(confusion_matrix(df_test['sentiment_label'], y_pred_tfidf_simple))\n",
        "#print(classification_report(df_test['sentiment_label'], y_pred_tfidf_simple))"
      ],
      "metadata": {
        "id": "jMPyk7SHvEZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('TfIdfVectorizer complejo\\n')\n",
        "print(confusion_matrix(df_test['sentiment_label'], y_pred_tfidf_complex))\n",
        "print(classification_report(df_test['sentiment_label'], y_pred_tfidf_complex))"
      ],
      "metadata": {
        "id": "WL9aja-xvHD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wahQ0kz0WvcN"
      },
      "outputs": [],
      "source": [
        "#Frecuencia de las palabras. Observamos algunos outliers. \n",
        "#Esos datos tienen q ser significativos dado que se ha realizado un preprocesamiento previo\n",
        "plt.plot(X_train_cv_complex[5,:]) #CountVectorized train en array\n",
        "plt.xlabel('Word')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDD50OJ-vVOV"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Observamos la ley de Zipf\n",
        "word_freq = X_train_cv_complex.sum(axis=0)\n",
        "\n",
        "sorted_word_freq = np.sort(word_freq)[::-1]\n",
        "\n",
        "plt.plot(sorted_word_freq)\n",
        "plt.gca().set_xscale('log')\n",
        "plt.gca().set_yscale('log')\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Number of occurrences')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpVHk7N3vdoE"
      },
      "outputs": [],
      "source": [
        "import sklearn.preprocessing as pr\n",
        "###NORMALIZAAAAAAA!!!!\n",
        "\n",
        "features_train = pr.normalize(X_train_cv_complex, axis=1)\n",
        "features_test = pr.normalize(X_test_cv_complex, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ESTA PARTE ES MOSTRAR DATOS SOLO\n",
        "cv = TfidfVectorizer(\n",
        "    max_df=0.95,\n",
        "    min_df=3,\n",
        "    max_features=2500,\n",
        "    strip_accents='ascii',\n",
        "    ngram_range=(1, 3)\n",
        ")\n",
        "cv.fit(X_train)"
      ],
      "metadata": {
        "id": "Po3b5XJ_FlqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(cv.vocabulary_.items())[:20])"
      ],
      "metadata": {
        "id": "-hPR5Fpjb9Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(cv.vocabulary_))"
      ],
      "metadata": {
        "id": "v8Cgm6axcZ10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF scores del training set y test set"
      ],
      "metadata": {
        "id": "nKKOzkU_dQPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SI YA HE NORMALIZADO ANTES, normalizamos OTRA VEZ??? los conjutos de entrenamiento y test\n",
        "X_train_ = cv.transform(X_train)\n",
        "X_test_ = cv.transform(X_test)"
      ],
      "metadata": {
        "id": "cMsd38UJdRth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Score IDF de algunas palabras"
      ],
      "metadata": {
        "id": "GiyUSlEFdf3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_example = [\n",
        "    'sauce',\n",
        "    'very',\n",
        "    'good',\n",
        "    'amazing',\n",
        "    'great',\n",
        "    'fresh',\n",
        "    'fish',\n",
        "    'deviled',\n",
        "    'but',\n",
        "    'was',\n",
        "    'never',\n",
        "    'not',\n",
        "    'wasn´t'\n",
        "]"
      ],
      "metadata": {
        "id": "TvkGy7X6dhD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_idf = dict(zip(cv.get_feature_names(), cv.idf_))\n",
        "\n",
        "print('{0:20}{1:20}'.format('Palabra', 'IDF'))\n",
        "for word in words_example:\n",
        "    if word not in vocab_idf:\n",
        "        print('{0:20}{1:20}'.format(word, 'OOV'))\n",
        "    else:\n",
        "        print('{0:20}{1:2.3f}'.format(word, vocab_idf[word]))"
      ],
      "metadata": {
        "id": "SGu3EA9Yg2aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Palabras con el TF-IDF en alguna review"
      ],
      "metadata": {
        "id": "xJrkXLcGhYrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = random.randint(0, len(X_train))\n",
        "print('ID: {}'.format(i))\n",
        "print('Sentiment: {}'.format(y_train.iloc[i]))\n",
        "print('Review: {}'.format(X_train.iloc[i]))"
      ],
      "metadata": {
        "id": "hQbXbg45hCl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_vector = X_train_[i]\n",
        "df_tfidf = pd.DataFrame(doc_vector.T.todense(), index=cv.get_feature_names(), columns=['tfidf'])\n",
        "df_tfidf = df_tfidf[df_tfidf['tfidf'] > 0]\n",
        "\n",
        "top_n = 10\n",
        "print('Top {} words with highest TF_IDF in the review {}:\\n{}'.format(top_n, i, df_tfidf.sort_values(by=[\"tfidf\"],ascending=False)[:top_n]))\n",
        "print('\\nTop {} words with lowest TF_IDF in the review {}:\\n{}'.format(top_n, i, df_tfidf.sort_values(by=[\"tfidf\"],ascending=False)[-top_n:]))"
      ],
      "metadata": {
        "id": "PqTMFc4Ahu0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## χ²  scores"
      ],
      "metadata": {
        "id": "pRPsmFkZiD2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the chi-squared score for each word in the training set and show the values\n",
        "i = 15\n",
        "\n",
        "chi2score = chi2(X_train_, y_train)[0]\n",
        "scores = list(zip(cv.get_feature_names(), chi2score))\n",
        "sorted_scores = sorted(scores, key=lambda x:x[1])\n",
        "topchi2 = list(zip(*sorted_scores[-i:]))\n",
        "x = range(len(topchi2[1]))\n",
        "labels = topchi2[0]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.barh(x,topchi2[1], align='center', alpha=0.5)\n",
        "plt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\n",
        "plt.yticks(x, labels, fontsize=12)\n",
        "plt.xlabel('$\\chi^2$', fontsize=26)\n",
        "plt.ylabel('word', fontsize=16)\n",
        "plt.title('Top {} $\\chi^2$ score for each word in the training set'.format(i), fontsize=20)\n",
        "plt.grid()\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "kViDDtraiA6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "0cgjiZecigrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Hacemos una regresión logistica\n",
        "c_params = [0.01, 0.05, 0.25, 0.5, 1, 10, 100, 1000, 10000]\n",
        "\n",
        "train_acc = list()\n",
        "test_acc = list()\n",
        "for c in c_params:\n",
        "    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=500)\n",
        "    lr.fit(X_train_, y_train)\n",
        "    \n",
        "    train_predict = lr.predict(X_train_)\n",
        "    test_predict = lr.predict(X_test_)\n",
        "    \n",
        "    print (\"Accuracy for C={}: {}\".format(c, accuracy_score(y_test, test_predict)))\n",
        "    \n",
        "    train_acc.append(accuracy_score(y_train, train_predict))\n",
        "    test_acc.append(accuracy_score(y_test, test_predict))"
      ],
      "metadata": {
        "id": "aJuAKu9XiKze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imprimimos las métricas\n",
        "print('Confussion matrix:\\n{}'.format(confusion_matrix(y_test, test_predict)))\n",
        "print('\\nClassification report:\\n{}'.format(classification_report(y_test, test_predict)))\n",
        "print('Accuracy score:{}'.format(accuracy_score(y_test, test_predict)))"
      ],
      "metadata": {
        "id": "n4bzpcUditwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ploteamos\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(train_acc, label='train')\n",
        "plt.plot(test_acc, label='test')\n",
        "plt.axvline(np.argmax(test_acc), c='g', ls='--', alpha=0.8)\n",
        "plt.title('Accuracy evolution for different C values')\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.xticks(list(range(len(c_params))), c_params)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XUTbIZLHjDKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p, r, thresholds = precision_recall_curve(y_test, test_predict)"
      ],
      "metadata": {
        "id": "04p10fNcjWVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n",
        "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
        "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.xlabel(\"Decision Threshold\")\n",
        "    plt.legend(loc='best')"
      ],
      "metadata": {
        "id": "4LmXAHkhjclB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_precision_recall_vs_threshold(p, r, thresholds)"
      ],
      "metadata": {
        "id": "7_6yCrIrjp7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predicción"
      ],
      "metadata": {
        "id": "iImGxaDqjyvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_review_sentiment(review_index, model):\n",
        "    print('Actual sentiment: {}'.format(df_train.iloc[review_index]['sentiment_label']))\n",
        "    r = df_train.iloc[review_index]['review_text']\n",
        "    print('Prediction: {}'.format(lr.predict(cv.transform([r]))))"
      ],
      "metadata": {
        "id": "Fj7bdi9Aj1EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in random.sample(range(0, len(df_train)), 5):\n",
        "    print('\\nReview no. {}'.format(i))\n",
        "    predict_review_sentiment(i, lr)"
      ],
      "metadata": {
        "id": "DsS4bAv9j4e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo nuevo"
      ],
      "metadata": {
        "id": "tOEsuWzgzpmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#xgboost \n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "labels_train= df_train['sentiment_label']\n",
        "labels_test= df_test['sentiment_label']\n",
        "n_estimators = 32\n",
        "\n",
        "def classify_gboost(X_train, X_test, y_train, y_test):        \n",
        "    clf = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=1.0, max_depth=1, random_state=42)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "    \n",
        "    print(\"[{}] Accuracy: train = {}, test = {}\".format(\n",
        "            clf.__class__.__name__,\n",
        "            clf.score(X_train, y_train),\n",
        "            clf.score(X_test, y_test)))\n",
        "    \n",
        "    return clf\n",
        "\n",
        "\n",
        "clf2 = classify_gboost(features_train, features_test, labels_train, labels_test)"
      ],
      "metadata": {
        "id": "R8uN_wYfzsBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}